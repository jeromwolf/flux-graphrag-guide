{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7: 평가와 프로덕션 — GraphRAG 실무 적용 가이드\n",
    "\n",
    "**소요시간**: 1시간 | **난이도**: ★★★★ | **시리즈 최종편**\n",
    "\n",
    "---\n",
    "\n",
    "Part 1~6에서 구축한 GraphRAG 시스템의 **품질을 정량 평가**하고,  \n",
    "**프로덕션 배포를 위한 최적화와 운영 체크리스트**를 완성합니다.\n",
    "\n",
    "| 섹션 | 내용 | 시간 |\n",
    "|------|------|------|\n",
    "| 1 | 환경 설정 | 5분 |\n",
    "| 2 | RAGAS 4대 메트릭 이해 | 10분 |\n",
    "| 3 | 질문 난이도별 평가 | 15분 |\n",
    "| 4 | Vector RAG vs GraphRAG 비교 | 10분 |\n",
    "| 5 | Neo4j 성능 최적화 | 10분 |\n",
    "| 6 | 프로덕션 체크리스트 | 5분 |\n",
    "| 7 | 최종 아키텍처 요약 | 3분 |\n",
    "| 8 | 연습 문제 | 2분 |\n",
    "\n",
    "> **이 노트북은 7개 시리즈의 마지막입니다.**  \n",
    "> Part 1의 회색 아키텍처가 이제 전부 컬러로 채워집니다."
   ],
   "id": "intro-001"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. 환경 설정\n",
    "\n",
    "RAGAS 평가 프레임워크, Neo4j, OpenAI를 연결하고 평가 질문 데이터를 로드합니다."
   ],
   "id": "sec1-title"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 1-1. 패키지 임포트\n",
    "# ============================================================\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from neo4j import GraphDatabase\n",
    "from openai import OpenAI\n",
    "\n",
    "# RAGAS 평가 메트릭\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 설정 (matplotlib)\n",
    "matplotlib.rcParams['font.family'] = 'AppleGothic'  # macOS\n",
    "# matplotlib.rcParams['font.family'] = 'Malgun Gothic'  # Windows\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"패키지 로드 완료\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec1-imports"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 1-2. 환경변수 로드 및 클라이언트 초기화\n",
    "# ============================================================\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI 클라이언트\n",
    "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Neo4j 연결\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\", \"bolt://localhost:7687\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USER\", \"neo4j\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\", \"graphrag2024\")\n",
    "\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "# 연결 테스트\n",
    "with driver.session() as session:\n",
    "    result = session.run(\"RETURN 1 AS test\")\n",
    "    assert result.single()[\"test\"] == 1\n",
    "    print(\"Neo4j 연결 성공\")\n",
    "\n",
    "print(f\"OpenAI API 키: ...{os.getenv('OPENAI_API_KEY', 'NOT_SET')[-4:]}\")\n",
    "print(f\"Neo4j URI: {NEO4J_URI}\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec1-env"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 1-3. 평가 질문 데이터 로드\n",
    "# ============================================================\n",
    "# data/eval_questions.json 파일이 있으면 로드, 없으면 내장 데이터 사용\n",
    "eval_path = Path(\"data/eval_questions.json\")\n",
    "\n",
    "if eval_path.exists():\n",
    "    with open(eval_path, encoding=\"utf-8\") as f:\n",
    "        eval_data = json.load(f)\n",
    "    print(f\"평가 질문 로드 완료: {len(eval_data)}개\")\n",
    "else:\n",
    "    # 내장 평가 데이터셋 (30개: Easy 10, Medium 10, Hard 10)\n",
    "    eval_data = [\n",
    "        # === Easy (1-hop) 질문 10개 ===\n",
    "        {\"question\": \"삼성전자가 양산을 시작한 차세대 메모리는?\",\n",
    "         \"ground_truth\": \"HBM4\", \"difficulty\": \"easy\", \"hops\": 1},\n",
    "        {\"question\": \"네이버가 출시한 기업용 AI 에이전트 이름은?\",\n",
    "         \"ground_truth\": \"CLOVA for Enterprise\", \"difficulty\": \"easy\", \"hops\": 1},\n",
    "        {\"question\": \"SK하이닉스가 인수한 인텔 사업부는?\",\n",
    "         \"ground_truth\": \"NAND 플래시 사업부 (솔리다임)\", \"difficulty\": \"easy\", \"hops\": 1},\n",
    "        {\"question\": \"카카오가 투자한 자율주행 스타트업은?\",\n",
    "         \"ground_truth\": \"오토노머스에이투지\", \"difficulty\": \"easy\", \"hops\": 1},\n",
    "        {\"question\": \"LG에너지솔루션이 착공한 미국 공장 위치는?\",\n",
    "         \"ground_truth\": \"애리조나주 퀸크릭\", \"difficulty\": \"easy\", \"hops\": 1},\n",
    "        {\"question\": \"현대자동차가 스마트팩토리에 투입한 로봇 이름은?\",\n",
    "         \"ground_truth\": \"스팟(Spot)\", \"difficulty\": \"easy\", \"hops\": 1},\n",
    "        {\"question\": \"카카오뱅크 AI 어드바이저가 활용한 모델은?\",\n",
    "         \"ground_truth\": \"GPT-4o\", \"difficulty\": \"easy\", \"hops\": 1},\n",
    "        {\"question\": \"LG AI연구원이 공개한 의료 AI 모델 이름은?\",\n",
    "         \"ground_truth\": \"엑사원 메드(EXAONE Med)\", \"difficulty\": \"easy\", \"hops\": 1},\n",
    "        {\"question\": \"쿠팡이 도입 예정인 물류 로봇 수량은?\",\n",
    "         \"ground_truth\": \"500대 이상\", \"difficulty\": \"easy\", \"hops\": 1},\n",
    "        {\"question\": \"HBM4가 탑재될 NVIDIA GPU 이름은?\",\n",
    "         \"ground_truth\": \"Blackwell Ultra\", \"difficulty\": \"easy\", \"hops\": 1},\n",
    "\n",
    "        # === Medium (2-hop) 질문 10개 ===\n",
    "        {\"question\": \"네이버와 클라우드 인프라 협력을 한 기업이 속한 그룹은?\",\n",
    "         \"ground_truth\": \"삼성그룹 (삼성SDS)\", \"difficulty\": \"medium\", \"hops\": 2},\n",
    "        {\"question\": \"삼성전자 HBM4가 탑재될 GPU를 만드는 회사의 본사 위치는?\",\n",
    "         \"ground_truth\": \"미국 산타클라라 (NVIDIA)\", \"difficulty\": \"medium\", \"hops\": 2},\n",
    "        {\"question\": \"카카오가 투자한 자율주행 기업의 기술 레벨은?\",\n",
    "         \"ground_truth\": \"레벨4\", \"difficulty\": \"medium\", \"hops\": 2},\n",
    "        {\"question\": \"LG에너지솔루션 배터리를 공급받을 자동차 회사의 CEO는?\",\n",
    "         \"ground_truth\": \"일론 머스크 (테슬라)\", \"difficulty\": \"medium\", \"hops\": 2},\n",
    "        {\"question\": \"현대자동차가 인수한 로봇 기업의 대표 제품은?\",\n",
    "         \"ground_truth\": \"스팟(Spot) - 보스턴다이내믹스\", \"difficulty\": \"medium\", \"hops\": 2},\n",
    "        {\"question\": \"엑사원 메드를 공동 개발한 병원들이 위치한 도시는?\",\n",
    "         \"ground_truth\": \"서울 (서울대병원, 아산병원)\", \"difficulty\": \"medium\", \"hops\": 2},\n",
    "        {\"question\": \"쿠팡과 파트너십을 맺은 물류 로봇 기업의 국적은?\",\n",
    "         \"ground_truth\": \"중국 (긱플러스)\", \"difficulty\": \"medium\", \"hops\": 2},\n",
    "        {\"question\": \"온디바이스 AI MOU를 체결한 두 기업의 대표 직함은?\",\n",
    "         \"ground_truth\": \"이재용 회장, 최수연 대표\", \"difficulty\": \"medium\", \"hops\": 2},\n",
    "        {\"question\": \"NAND 사업부 인수 금액과 인수한 기업의 CEO 이름은?\",\n",
    "         \"ground_truth\": \"90억 달러, 곽노정\", \"difficulty\": \"medium\", \"hops\": 2},\n",
    "        {\"question\": \"카카오뱅크가 받은 금융위원회 지정과 가입자 수는?\",\n",
    "         \"ground_truth\": \"혁신금융서비스 지정, 50만 명\", \"difficulty\": \"medium\", \"hops\": 2},\n",
    "\n",
    "        # === Hard (3-hop / Multi-hop) 질문 10개 ===\n",
    "        {\"question\": \"삼성전자와 네이버가 공동 개발한 기술이 적용될 기기 시리즈와 출시 연도는?\",\n",
    "         \"ground_truth\": \"갤럭시 S26, 2025년\", \"difficulty\": \"hard\", \"hops\": 3},\n",
    "        {\"question\": \"HBM4를 생산하는 기업과 HBM 시장에서 경쟁하는 기업이 공통으로 속한 산업 분류는?\",\n",
    "         \"ground_truth\": \"반도체 (삼성전자, SK하이닉스)\", \"difficulty\": \"hard\", \"hops\": 3},\n",
    "        {\"question\": \"보스턴다이내믹스를 인수한 자동차 기업이 로봇을 투입한 공장 위치와 로봇 수량은?\",\n",
    "         \"ground_truth\": \"울산 공장, 스팟 20대\", \"difficulty\": \"hard\", \"hops\": 3},\n",
    "        {\"question\": \"AI 에이전트를 출시한 기업과 온디바이스 MOU를 체결한 상대 기업의 반도체 제품명은?\",\n",
    "         \"ground_truth\": \"네이버-삼성전자 MOU, HBM4\", \"difficulty\": \"hard\", \"hops\": 3},\n",
    "        {\"question\": \"카카오 그룹에서 자율주행과 AI 금융 서비스를 각각 담당하는 자회사는?\",\n",
    "         \"ground_truth\": \"카카오모빌리티, 카카오뱅크\", \"difficulty\": \"hard\", \"hops\": 3},\n",
    "        {\"question\": \"LG 그룹에서 배터리와 AI를 담당하는 두 자회사의 해외 진출 지역은?\",\n",
    "         \"ground_truth\": \"LG에너지솔루션(미국 애리조나), LG AI연구원(글로벌 의료 AI)\",\n",
    "         \"difficulty\": \"hard\", \"hops\": 3},\n",
    "        {\"question\": \"테슬라에 배터리를 공급하는 기업의 CEO와 투자 금액, 그리고 IRA 보조금 관련 전략은?\",\n",
    "         \"ground_truth\": \"김동명, 55억 달러, IRA 보조금 극대화\", \"difficulty\": \"hard\", \"hops\": 3},\n",
    "        {\"question\": \"GPT-4o를 활용하는 두 서비스(금융, 의료)의 공통점과 차이점은?\",\n",
    "         \"ground_truth\": \"카카오뱅크 AI 어드바이저(금융) vs 엑사원 메드(의료) — 둘 다 LLM 활용, 도메인 특화\",\n",
    "         \"difficulty\": \"hard\", \"hops\": 3},\n",
    "        {\"question\": \"물류 자동화에 로봇을 도입한 두 기업의 예상 효과를 비교하면?\",\n",
    "         \"ground_truth\": \"쿠팡(처리속도 40% 향상, 인건비 30% 절감) vs 현대자동차(설비점검, 안전모니터링 자동화)\",\n",
    "         \"difficulty\": \"hard\", \"hops\": 3},\n",
    "        {\"question\": \"반도체 기업 두 곳의 CEO, 주력 제품, 경쟁 관계를 종합적으로 설명하면?\",\n",
    "         \"ground_truth\": \"삼성전자(전영현 부회장, HBM4) vs SK하이닉스(곽노정 CEO, NAND+HBM) — HBM 시장 경쟁\",\n",
    "         \"difficulty\": \"hard\", \"hops\": 3}\n",
    "    ]\n",
    "    print(f\"내장 평가 질문 로드 완료: {len(eval_data)}개\")\n",
    "\n",
    "# 난이도별 분류\n",
    "easy_qs = [q for q in eval_data if q[\"difficulty\"] == \"easy\"]\n",
    "medium_qs = [q for q in eval_data if q[\"difficulty\"] == \"medium\"]\n",
    "hard_qs = [q for q in eval_data if q[\"difficulty\"] == \"hard\"]\n",
    "\n",
    "print(f\"\\n난이도 분포:\")\n",
    "print(f\"  Easy  (1-hop): {len(easy_qs)}개\")\n",
    "print(f\"  Medium(2-hop): {len(medium_qs)}개\")\n",
    "print(f\"  Hard  (3-hop): {len(hard_qs)}개\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec1-data"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. RAGAS 4대 메트릭 이해\n",
    "\n",
    "RAGAS(Retrieval Augmented Generation Assessment)는 RAG 시스템 평가의 **사실상 표준**입니다.  \n",
    "4가지 메트릭으로 시스템 품질을 다각도로 측정합니다.\n",
    "\n",
    "| 메트릭 | 질문 | 측정 대상 | 범위 |\n",
    "|--------|------|-----------|------|\n",
    "| **Faithfulness** | 답변이 검색 결과에 근거하는가? | 환각(Hallucination) 방지 | 0~1 |\n",
    "| **Answer Relevancy** | 답변이 질문에 적절한가? | 답변 관련성 | 0~1 |\n",
    "| **Context Precision** | 검색된 문맥이 정확한가? | 검색 정밀도 | 0~1 |\n",
    "| **Context Recall** | 필요한 정보가 모두 검색됐는가? | 검색 재현율 | 0~1 |\n",
    "\n",
    "### 메트릭 해석 가이드\n",
    "\n",
    "- **Faithfulness 낮음** → LLM이 검색 결과 없이 답변을 지어내고 있음 (환각)\n",
    "- **Answer Relevancy 낮음** → 질문과 무관한 답변 생성 (프롬프트 개선 필요)\n",
    "- **Context Precision 낮음** → 불필요한 문맥이 많이 검색됨 (검색 필터링 필요)\n",
    "- **Context Recall 낮음** → 필요한 정보가 검색되지 않음 (인덱스 / 검색 전략 개선)"
   ],
   "id": "sec2-theory"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 2-1. 헬퍼 함수: Neo4j에서 서브그래프 검색 (GraphRAG 방식)\n",
    "# ============================================================\n",
    "def graph_search(question: str, depth: int = 2) -> list[str]:\n",
    "    \"\"\"질문에서 키워드를 추출하고 Neo4j에서 관련 서브그래프를 검색합니다.\n",
    "    \n",
    "    Part 6에서 구축한 GraphRAG 파이프라인을 재사용합니다.\n",
    "    - Text2Cypher 또는 키워드 기반 서브그래프 탐색\n",
    "    - depth만큼 이웃 노드를 확장\n",
    "    \"\"\"\n",
    "    # 1단계: LLM으로 질문에서 핵심 엔티티 추출\n",
    "    extraction = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"질문에서 핵심 엔티티(회사명, 인물명, 제품명)를 JSON 배열로 추출하세요. 예: [\\\"삼성전자\\\", \\\"HBM4\\\"]\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        entities = json.loads(extraction.choices[0].message.content)\n",
    "    except json.JSONDecodeError:\n",
    "        entities = [question.split()[0]]  # 폴백: 첫 단어\n",
    "    \n",
    "    # 2단계: Neo4j에서 엔티티 기반 서브그래프 검색\n",
    "    contexts = []\n",
    "    with driver.session() as session:\n",
    "        for entity in entities[:3]:  # 최대 3개 엔티티\n",
    "            # 퍼지 매칭으로 노드 검색 후 depth만큼 확장\n",
    "            query = \"\"\"\n",
    "            MATCH (n)\n",
    "            WHERE any(prop IN keys(n) WHERE toString(n[prop]) CONTAINS $entity)\n",
    "            OPTIONAL MATCH path = (n)-[*1..{depth}]-(m)\n",
    "            WITH n, collect(DISTINCT m) AS neighbors,\n",
    "                 collect(DISTINCT relationships(path)) AS rels\n",
    "            RETURN n, neighbors, rels\n",
    "            LIMIT 5\n",
    "            \"\"\".replace(\"{depth}\", str(depth))\n",
    "            \n",
    "            try:\n",
    "                result = session.run(query, entity=entity)\n",
    "                for record in result:\n",
    "                    node = record[\"n\"]\n",
    "                    # 노드 정보를 텍스트로 변환\n",
    "                    node_text = f\"[{':'.join(node.labels)}] {dict(node)}\"\n",
    "                    contexts.append(node_text)\n",
    "                    \n",
    "                    # 이웃 노드 정보 추가\n",
    "                    for neighbor in record[\"neighbors\"]:\n",
    "                        if neighbor:\n",
    "                            nb_text = f\"  -> [{':'.join(neighbor.labels)}] {dict(neighbor)}\"\n",
    "                            contexts.append(nb_text)\n",
    "            except Exception as e:\n",
    "                contexts.append(f\"검색 오류: {e}\")\n",
    "    \n",
    "    return contexts if contexts else [\"관련 정보를 찾을 수 없습니다.\"]\n",
    "\n",
    "\n",
    "def vector_search(question: str, top_k: int = 5) -> list[str]:\n",
    "    \"\"\"벡터 유사도 기반 검색 (Vector-only RAG 시뮬레이션).\n",
    "    \n",
    "    Neo4j 벡터 인덱스 또는 단순 텍스트 매칭으로 문서를 검색합니다.\n",
    "    GraphRAG와의 비교를 위해 그래프 탐색 없이 단일 문서만 반환합니다.\n",
    "    \"\"\"\n",
    "    contexts = []\n",
    "    with driver.session() as session:\n",
    "        # 벡터 인덱스가 없는 경우 텍스트 매칭으로 폴백\n",
    "        try:\n",
    "            # 풀텍스트 인덱스 활용 시도\n",
    "            result = session.run(\"\"\"\n",
    "                CALL db.index.fulltext.queryNodes('fulltext_index', $query)\n",
    "                YIELD node, score\n",
    "                RETURN node, score\n",
    "                ORDER BY score DESC\n",
    "                LIMIT $top_k\n",
    "            \"\"\", query=question, top_k=top_k)\n",
    "            \n",
    "            for record in result:\n",
    "                node = record[\"node\"]\n",
    "                contexts.append(f\"[{':'.join(node.labels)}] {dict(node)} (score: {record['score']:.3f})\")\n",
    "        except Exception:\n",
    "            # 풀텍스트 인덱스 없으면 단순 CONTAINS 검색\n",
    "            keywords = question.replace(\"?\", \"\").replace(\"은\", \"\").replace(\"는\", \"\").split()[:3]\n",
    "            for kw in keywords:\n",
    "                result = session.run(\"\"\"\n",
    "                    MATCH (n)\n",
    "                    WHERE any(prop IN keys(n) WHERE toString(n[prop]) CONTAINS $kw)\n",
    "                    RETURN n LIMIT 3\n",
    "                \"\"\", kw=kw)\n",
    "                for record in result:\n",
    "                    node = record[\"n\"]\n",
    "                    contexts.append(f\"[{':'.join(node.labels)}] {dict(node)}\")\n",
    "    \n",
    "    # 그래프 탐색 없이 개별 노드만 반환 (Vector RAG 특성)\n",
    "    return contexts[:top_k] if contexts else [\"관련 정보를 찾을 수 없습니다.\"]\n",
    "\n",
    "\n",
    "print(\"검색 함수 정의 완료\")\n",
    "print(\"  - graph_search(): 서브그래프 탐색 (GraphRAG)\")\n",
    "print(\"  - vector_search(): 단일 노드 매칭 (Vector RAG 시뮬레이션)\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec2-helpers"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 2-2. RAG 답변 생성 함수\n",
    "# ============================================================\n",
    "def generate_answer(question: str, contexts: list[str], model: str = \"gpt-4o-mini\") -> str:\n",
    "    \"\"\"검색된 문맥을 바탕으로 LLM이 답변을 생성합니다.\"\"\"\n",
    "    context_text = \"\\n\".join(contexts)\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": (\n",
    "                \"주어진 문맥 정보만을 사용하여 질문에 답변하세요.\\n\"\n",
    "                \"문맥에 없는 정보는 '정보가 부족합니다'라고 답하세요.\\n\"\n",
    "                \"한국어로 간결하게 답변하세요.\"\n",
    "            )},\n",
    "            {\"role\": \"user\", \"content\": f\"문맥:\\n{context_text}\\n\\n질문: {question}\"}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print(\"답변 생성 함수 정의 완료\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec2-generate"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 2-3. RAGAS 메트릭 개별 계산 예시\n",
    "# ============================================================\n",
    "# 단일 질문에 대해 각 메트릭을 개별 확인\n",
    "\n",
    "sample_q = eval_data[0]  # Easy 질문 1개\n",
    "print(f\"샘플 질문: {sample_q['question']}\")\n",
    "print(f\"정답: {sample_q['ground_truth']}\")\n",
    "print(f\"난이도: {sample_q['difficulty']} ({sample_q['hops']}-hop)\")\n",
    "print(\"---\")\n",
    "\n",
    "# GraphRAG로 검색 + 답변 생성\n",
    "sample_contexts = graph_search(sample_q[\"question\"])\n",
    "sample_answer = generate_answer(sample_q[\"question\"], sample_contexts)\n",
    "\n",
    "print(f\"검색된 문맥 수: {len(sample_contexts)}\")\n",
    "print(f\"생성된 답변: {sample_answer}\")\n",
    "print(\"---\")\n",
    "\n",
    "# RAGAS Dataset 형식으로 변환\n",
    "from datasets import Dataset\n",
    "\n",
    "sample_dataset = Dataset.from_dict({\n",
    "    \"question\": [sample_q[\"question\"]],\n",
    "    \"answer\": [sample_answer],\n",
    "    \"contexts\": [sample_contexts],\n",
    "    \"ground_truth\": [sample_q[\"ground_truth\"]]\n",
    "})\n",
    "\n",
    "# 각 메트릭 개별 평가\n",
    "print(\"\\n=== RAGAS 4대 메트릭 개별 결과 ===\")\n",
    "\n",
    "for metric_name, metric in [\n",
    "    (\"Faithfulness\", faithfulness),\n",
    "    (\"Answer Relevancy\", answer_relevancy),\n",
    "    (\"Context Precision\", context_precision),\n",
    "    (\"Context Recall\", context_recall)\n",
    "]:\n",
    "    try:\n",
    "        result = evaluate(sample_dataset, metrics=[metric])\n",
    "        score = list(result.values())[0]\n",
    "        bar = \"*\" * int(score * 20)\n",
    "        print(f\"  {metric_name:20s}: {score:.4f} |{bar}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  {metric_name:20s}: 평가 실패 - {e}\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec2-individual"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. 질문 난이도별 평가 (핵심)\n",
    "\n",
    "30개 질문을 **난이도별로 그룹화**하여 RAGAS 평가를 실행합니다.  \n",
    "GraphRAG의 진가는 **Hard(3-hop) 질문**에서 드러납니다.\n",
    "\n",
    "```\n",
    "Easy  (1-hop): \"삼성전자 CEO는?\"              → 벡터 RAG도 가능\n",
    "Medium(2-hop): \"삼성 투자기관은?\"              → GraphRAG 유리\n",
    "Hard  (3-hop): \"삼성 투자기관의 다른 투자처는?\" → GraphRAG만 가능\n",
    "```"
   ],
   "id": "sec3-title"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 3-1. 난이도별 RAG 파이프라인 실행 (GraphRAG)\n",
    "# ============================================================\n",
    "def run_rag_pipeline(questions: list[dict], search_fn, label: str) -> dict:\n",
    "    \"\"\"질문 리스트에 대해 RAG 파이프라인을 실행하고 결과를 반환합니다.\n",
    "    \n",
    "    Args:\n",
    "        questions: 질문 딕셔너리 리스트\n",
    "        search_fn: 검색 함수 (graph_search 또는 vector_search)\n",
    "        label: 결과 식별 라벨\n",
    "    Returns:\n",
    "        dict with 'dataset' (RAGAS용)과 'details' (상세 결과)\n",
    "    \"\"\"\n",
    "    all_questions = []\n",
    "    all_answers = []\n",
    "    all_contexts = []\n",
    "    all_ground_truths = []\n",
    "    details = []\n",
    "    \n",
    "    for i, q in enumerate(questions):\n",
    "        print(f\"  [{label}] {i+1}/{len(questions)}: {q['question'][:40]}...\", end=\" \")\n",
    "        \n",
    "        # 검색\n",
    "        start_time = time.time()\n",
    "        contexts = search_fn(q[\"question\"])\n",
    "        search_time = time.time() - start_time\n",
    "        \n",
    "        # 답변 생성\n",
    "        start_time = time.time()\n",
    "        answer = generate_answer(q[\"question\"], contexts)\n",
    "        gen_time = time.time() - start_time\n",
    "        \n",
    "        all_questions.append(q[\"question\"])\n",
    "        all_answers.append(answer)\n",
    "        all_contexts.append(contexts)\n",
    "        all_ground_truths.append(q[\"ground_truth\"])\n",
    "        \n",
    "        details.append({\n",
    "            \"question\": q[\"question\"],\n",
    "            \"answer\": answer,\n",
    "            \"ground_truth\": q[\"ground_truth\"],\n",
    "            \"difficulty\": q[\"difficulty\"],\n",
    "            \"hops\": q[\"hops\"],\n",
    "            \"context_count\": len(contexts),\n",
    "            \"search_time\": search_time,\n",
    "            \"gen_time\": gen_time\n",
    "        })\n",
    "        \n",
    "        print(f\"({search_time:.1f}s + {gen_time:.1f}s)\")\n",
    "    \n",
    "    dataset = Dataset.from_dict({\n",
    "        \"question\": all_questions,\n",
    "        \"answer\": all_answers,\n",
    "        \"contexts\": all_contexts,\n",
    "        \"ground_truth\": all_ground_truths\n",
    "    })\n",
    "    \n",
    "    return {\"dataset\": dataset, \"details\": details}\n",
    "\n",
    "print(\"파이프라인 함수 정의 완료\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec3-pipeline"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 3-2. Easy (1-hop) 질문 평가\n",
    "# ============================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"Easy (1-hop) 질문 10개 — GraphRAG 파이프라인\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "easy_results = run_rag_pipeline(easy_qs, graph_search, \"Easy\")\n",
    "\n",
    "print(\"\\nRAGAS 평가 중...\")\n",
    "easy_scores = evaluate(\n",
    "    easy_results[\"dataset\"],\n",
    "    metrics=[faithfulness, answer_relevancy, context_precision, context_recall]\n",
    ")\n",
    "print(\"\\n[Easy 결과]\")\n",
    "for metric, score in easy_scores.items():\n",
    "    print(f\"  {metric}: {score:.4f}\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec3-easy"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 3-3. Medium (2-hop) 질문 평가\n",
    "# ============================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"Medium (2-hop) 질문 10개 — GraphRAG 파이프라인\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "medium_results = run_rag_pipeline(medium_qs, graph_search, \"Medium\")\n",
    "\n",
    "print(\"\\nRAGAS 평가 중...\")\n",
    "medium_scores = evaluate(\n",
    "    medium_results[\"dataset\"],\n",
    "    metrics=[faithfulness, answer_relevancy, context_precision, context_recall]\n",
    ")\n",
    "print(\"\\n[Medium 결과]\")\n",
    "for metric, score in medium_scores.items():\n",
    "    print(f\"  {metric}: {score:.4f}\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec3-medium"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 3-4. Hard (3-hop) 질문 평가\n",
    "# ============================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"Hard (3-hop) 질문 10개 — GraphRAG 파이프라인\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "hard_results = run_rag_pipeline(hard_qs, graph_search, \"Hard\")\n",
    "\n",
    "print(\"\\nRAGAS 평가 중...\")\n",
    "hard_scores = evaluate(\n",
    "    hard_results[\"dataset\"],\n",
    "    metrics=[faithfulness, answer_relevancy, context_precision, context_recall]\n",
    ")\n",
    "print(\"\\n[Hard 결과]\")\n",
    "for metric, score in hard_scores.items():\n",
    "    print(f\"  {metric}: {score:.4f}\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec3-hard"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 3-5. 난이도별 메트릭 비교 DataFrame + 시각화\n",
    "# ============================================================\n",
    "\n",
    "# DataFrame 구성\n",
    "metrics_list = [\"faithfulness\", \"answer_relevancy\", \"context_precision\", \"context_recall\"]\n",
    "\n",
    "comparison_data = {\n",
    "    \"Metric\": metrics_list,\n",
    "    \"Easy (1-hop)\": [easy_scores.get(m, 0) for m in metrics_list],\n",
    "    \"Medium (2-hop)\": [medium_scores.get(m, 0) for m in metrics_list],\n",
    "    \"Hard (3-hop)\": [hard_scores.get(m, 0) for m in metrics_list],\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "df_comparison = df_comparison.set_index(\"Metric\")\n",
    "\n",
    "print(\"\\n=== 난이도별 RAGAS 메트릭 비교 ===\")\n",
    "print(df_comparison.round(4).to_string())\n",
    "print(\"\\n평균:\")\n",
    "print(df_comparison.mean().round(4).to_string())"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec3-df"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 3-6. 히트맵 + 바 차트 시각화\n",
    "# ============================================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# --- 히트맵 ---\n",
    "ax1 = axes[0]\n",
    "im = ax1.imshow(df_comparison.values, cmap=\"RdYlGn\", aspect=\"auto\", vmin=0, vmax=1)\n",
    "\n",
    "ax1.set_xticks(range(len(df_comparison.columns)))\n",
    "ax1.set_xticklabels(df_comparison.columns, fontsize=11)\n",
    "ax1.set_yticks(range(len(df_comparison.index)))\n",
    "ax1.set_yticklabels(df_comparison.index, fontsize=11)\n",
    "\n",
    "# 셀 값 표시\n",
    "for i in range(len(df_comparison.index)):\n",
    "    for j in range(len(df_comparison.columns)):\n",
    "        val = df_comparison.values[i, j]\n",
    "        color = \"white\" if val < 0.5 else \"black\"\n",
    "        ax1.text(j, i, f\"{val:.3f}\", ha=\"center\", va=\"center\",\n",
    "                fontsize=12, fontweight=\"bold\", color=color)\n",
    "\n",
    "ax1.set_title(\"난이도별 RAGAS 메트릭 히트맵\", fontsize=14, fontweight=\"bold\")\n",
    "plt.colorbar(im, ax=ax1, shrink=0.8)\n",
    "\n",
    "# --- 그룹 바 차트 ---\n",
    "ax2 = axes[1]\n",
    "x = np.arange(len(metrics_list))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax2.bar(x - width, df_comparison[\"Easy (1-hop)\"], width, label=\"Easy (1-hop)\", color=\"#22c55e\")\n",
    "bars2 = ax2.bar(x, df_comparison[\"Medium (2-hop)\"], width, label=\"Medium (2-hop)\", color=\"#f59e0b\")\n",
    "bars3 = ax2.bar(x + width, df_comparison[\"Hard (3-hop)\"], width, label=\"Hard (3-hop)\", color=\"#ef4444\")\n",
    "\n",
    "ax2.set_xlabel(\"메트릭\", fontsize=12)\n",
    "ax2.set_ylabel(\"점수\", fontsize=12)\n",
    "ax2.set_title(\"난이도별 GraphRAG 성능 비교\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels([\"Faithful\", \"Relevancy\", \"Precision\", \"Recall\"], fontsize=10)\n",
    "ax2.set_ylim(0, 1.1)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"data/difficulty_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"차트 저장: data/difficulty_comparison.png\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec3-viz"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Vector RAG vs GraphRAG 비교\n",
    "\n",
    "**동일한 질문셋**에 대해 두 가지 검색 전략을 비교합니다.\n",
    "\n",
    "| 검색 방식 | 특징 | 1-hop | 2-hop | 3-hop |\n",
    "|-----------|------|-------|-------|-------|\n",
    "| **Vector RAG** | 유사 문서 Top-K 반환 | 잘 됨 | 불안정 | 어려움 |\n",
    "| **GraphRAG** | 서브그래프 탐색 | 잘 됨 | 잘 됨 | 잘 됨 |\n",
    "\n",
    "**핵심 가설**: 1-hop에서는 비슷하지만, 3-hop에서 GraphRAG가 압도적으로 우세합니다."
   ],
   "id": "sec4-title"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 4-1. Vector RAG 파이프라인 실행 (동일 질문셋)\n",
    "# ============================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"Vector RAG — 전체 30개 질문\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Vector RAG로 Easy 질문\n",
    "print(\"\\n--- Easy ---\")\n",
    "vec_easy = run_rag_pipeline(easy_qs, vector_search, \"Vec-Easy\")\n",
    "vec_easy_scores = evaluate(\n",
    "    vec_easy[\"dataset\"],\n",
    "    metrics=[faithfulness, answer_relevancy, context_precision, context_recall]\n",
    ")\n",
    "\n",
    "# Vector RAG로 Medium 질문\n",
    "print(\"\\n--- Medium ---\")\n",
    "vec_medium = run_rag_pipeline(medium_qs, vector_search, \"Vec-Med\")\n",
    "vec_medium_scores = evaluate(\n",
    "    vec_medium[\"dataset\"],\n",
    "    metrics=[faithfulness, answer_relevancy, context_precision, context_recall]\n",
    ")\n",
    "\n",
    "# Vector RAG로 Hard 질문\n",
    "print(\"\\n--- Hard ---\")\n",
    "vec_hard = run_rag_pipeline(hard_qs, vector_search, \"Vec-Hard\")\n",
    "vec_hard_scores = evaluate(\n",
    "    vec_hard[\"dataset\"],\n",
    "    metrics=[faithfulness, answer_relevancy, context_precision, context_recall]\n",
    ")\n",
    "\n",
    "print(\"\\nVector RAG 평가 완료\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec4-vector"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 4-2. Vector RAG vs GraphRAG 비교 DataFrame\n",
    "# ============================================================\n",
    "\n",
    "def avg_score(scores_dict: dict) -> float:\n",
    "    \"\"\"메트릭 딕셔너리의 평균 점수를 계산합니다.\"\"\"\n",
    "    vals = [v for v in scores_dict.values() if isinstance(v, (int, float))]\n",
    "    return sum(vals) / len(vals) if vals else 0\n",
    "\n",
    "comparison_vs = pd.DataFrame({\n",
    "    \"난이도\": [\"Easy (1-hop)\", \"Medium (2-hop)\", \"Hard (3-hop)\"],\n",
    "    \"Vector RAG 평균\": [\n",
    "        avg_score(vec_easy_scores),\n",
    "        avg_score(vec_medium_scores),\n",
    "        avg_score(vec_hard_scores)\n",
    "    ],\n",
    "    \"GraphRAG 평균\": [\n",
    "        avg_score(easy_scores),\n",
    "        avg_score(medium_scores),\n",
    "        avg_score(hard_scores)\n",
    "    ]\n",
    "})\n",
    "comparison_vs[\"차이 (GraphRAG - Vector)\"] = comparison_vs[\"GraphRAG 평균\"] - comparison_vs[\"Vector RAG 평균\"]\n",
    "\n",
    "print(\"=== Vector RAG vs GraphRAG 비교 ===\")\n",
    "print(comparison_vs.round(4).to_string(index=False))\n",
    "\n",
    "# 메트릭별 상세 비교\n",
    "print(\"\\n=== 메트릭별 상세 비교 ===\")\n",
    "detail_rows = []\n",
    "for diff, v_scores, g_scores in [\n",
    "    (\"Easy\", vec_easy_scores, easy_scores),\n",
    "    (\"Medium\", vec_medium_scores, medium_scores),\n",
    "    (\"Hard\", vec_hard_scores, hard_scores)\n",
    "]:\n",
    "    for m in metrics_list:\n",
    "        detail_rows.append({\n",
    "            \"난이도\": diff,\n",
    "            \"메트릭\": m,\n",
    "            \"Vector\": v_scores.get(m, 0),\n",
    "            \"Graph\": g_scores.get(m, 0),\n",
    "            \"차이\": g_scores.get(m, 0) - v_scores.get(m, 0)\n",
    "        })\n",
    "\n",
    "df_detail = pd.DataFrame(detail_rows)\n",
    "print(df_detail.round(4).to_string(index=False))"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec4-compare-df"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 4-3. 비교 차트: \"1-hop 비슷, 3-hop GraphRAG 우세\" 패턴 확인\n",
    "# ============================================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "difficulties = [\"Easy\\n(1-hop)\", \"Medium\\n(2-hop)\", \"Hard\\n(3-hop)\"]\n",
    "x = np.arange(len(difficulties))\n",
    "width = 0.35\n",
    "\n",
    "# --- 평균 점수 비교 ---\n",
    "ax1 = axes[0]\n",
    "ax1.bar(x - width/2, comparison_vs[\"Vector RAG 평균\"], width,\n",
    "        label=\"Vector RAG\", color=\"#94a3b8\", edgecolor=\"#64748b\")\n",
    "ax1.bar(x + width/2, comparison_vs[\"GraphRAG 평균\"], width,\n",
    "        label=\"GraphRAG\", color=\"#3b82f6\", edgecolor=\"#1d4ed8\")\n",
    "\n",
    "ax1.set_ylabel(\"평균 RAGAS 점수\", fontsize=12)\n",
    "ax1.set_title(\"Vector RAG vs GraphRAG\\n난이도별 평균 성능\", fontsize=14, fontweight=\"bold\")\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(difficulties, fontsize=11)\n",
    "ax1.set_ylim(0, 1.1)\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "# 차이 표시 화살표\n",
    "for i, row in comparison_vs.iterrows():\n",
    "    diff = row[\"차이 (GraphRAG - Vector)\"]\n",
    "    if diff > 0:\n",
    "        ax1.annotate(f\"+{diff:.2f}\",\n",
    "                    xy=(i + width/2, row[\"GraphRAG 평균\"]),\n",
    "                    xytext=(i + width/2, row[\"GraphRAG 평균\"] + 0.05),\n",
    "                    ha=\"center\", fontsize=10, fontweight=\"bold\", color=\"#16a34a\")\n",
    "\n",
    "# --- Context Recall 비교 (GraphRAG 강점 메트릭) ---\n",
    "ax2 = axes[1]\n",
    "vec_recall = [vec_easy_scores.get(\"context_recall\", 0),\n",
    "              vec_medium_scores.get(\"context_recall\", 0),\n",
    "              vec_hard_scores.get(\"context_recall\", 0)]\n",
    "graph_recall = [easy_scores.get(\"context_recall\", 0),\n",
    "                medium_scores.get(\"context_recall\", 0),\n",
    "                hard_scores.get(\"context_recall\", 0)]\n",
    "\n",
    "ax2.plot(difficulties, vec_recall, \"o-\", color=\"#94a3b8\", linewidth=2,\n",
    "         markersize=10, label=\"Vector RAG\", markeredgecolor=\"#64748b\")\n",
    "ax2.plot(difficulties, graph_recall, \"s-\", color=\"#3b82f6\", linewidth=2,\n",
    "         markersize=10, label=\"GraphRAG\", markeredgecolor=\"#1d4ed8\")\n",
    "\n",
    "ax2.fill_between(range(3), vec_recall, graph_recall,\n",
    "                 alpha=0.15, color=\"#3b82f6\")\n",
    "\n",
    "ax2.set_ylabel(\"Context Recall\", fontsize=12)\n",
    "ax2.set_title(\"Context Recall 비교\\n(GraphRAG 강점 메트릭)\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.set_ylim(0, 1.1)\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"data/vector_vs_graph_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n핵심 발견:\")\n",
    "print(\"  - Easy(1-hop): 두 방식의 차이가 작음\")\n",
    "print(\"  - Hard(3-hop): GraphRAG가 Context Recall에서 크게 우세\")\n",
    "print(\"  -> Multi-hop 추론이 필요한 질문에서 GraphRAG의 존재 이유가 드러남\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec4-chart"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Neo4j 성능 최적화\n",
    "\n",
    "프로덕션 환경에서 GraphRAG의 응답 속도를 결정하는 것은 **Neo4j 쿼리 성능**입니다.  \n",
    "인덱스, APOC, 실행 계획 분석으로 최적화합니다."
   ],
   "id": "sec5-title"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 5-1. 인덱스 생성: CREATE INDEX, CREATE FULLTEXT INDEX\n",
    "# ============================================================\n",
    "with driver.session() as session:\n",
    "    # 기존 인덱스 확인\n",
    "    existing = session.run(\"SHOW INDEXES YIELD name RETURN collect(name) AS names\")\n",
    "    existing_names = existing.single()[\"names\"]\n",
    "    print(f\"기존 인덱스: {existing_names}\")\n",
    "    \n",
    "    # --- 노드 프로퍼티 인덱스 ---\n",
    "    index_commands = [\n",
    "        # 회사 이름 인덱스 (가장 자주 검색)\n",
    "        \"CREATE INDEX company_name IF NOT EXISTS FOR (c:Company) ON (c.name)\",\n",
    "        # 인물 이름 인덱스\n",
    "        \"CREATE INDEX person_name IF NOT EXISTS FOR (p:Person) ON (p.name)\",\n",
    "        # 제품 이름 인덱스\n",
    "        \"CREATE INDEX product_name IF NOT EXISTS FOR (p:Product) ON (p.name)\",\n",
    "        # 기사 ID 인덱스\n",
    "        \"CREATE INDEX article_id IF NOT EXISTS FOR (a:Article) ON (a.id)\",\n",
    "    ]\n",
    "    \n",
    "    for cmd in index_commands:\n",
    "        try:\n",
    "            session.run(cmd)\n",
    "            idx_name = cmd.split(\"INDEX\")[1].split(\"IF\")[0].strip()\n",
    "            print(f\"  인덱스 생성: {idx_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  인덱스 스킵 (이미 존재): {e}\")\n",
    "    \n",
    "    # --- 풀텍스트 인덱스 (자연어 검색용) ---\n",
    "    try:\n",
    "        session.run(\"\"\"\n",
    "            CREATE FULLTEXT INDEX fulltext_index IF NOT EXISTS\n",
    "            FOR (n:Company|Person|Product|Article)\n",
    "            ON EACH [n.name, n.title, n.content, n.description]\n",
    "        \"\"\")\n",
    "        print(\"  풀텍스트 인덱스 생성: fulltext_index\")\n",
    "    except Exception as e:\n",
    "        print(f\"  풀텍스트 인덱스 스킵: {e}\")\n",
    "    \n",
    "    # 최종 인덱스 목록\n",
    "    result = session.run(\"SHOW INDEXES YIELD name, type, labelsOrTypes, properties RETURN *\")\n",
    "    print(\"\\n=== 현재 인덱스 목록 ===\")\n",
    "    for record in result:\n",
    "        print(f\"  {record['name']:30s} | {record['type']:15s} | {record['labelsOrTypes']} -> {record['properties']}\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec5-index"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 5-2. 인덱스 전/후 쿼리 시간 비교 (10회 반복 측정)\n",
    "# ============================================================\n",
    "def benchmark_query(session, query: str, params: dict = None, n_runs: int = 10) -> list[float]:\n",
    "    \"\"\"쿼리를 n_runs번 실행하고 각 실행 시간(ms)을 반환합니다.\"\"\"\n",
    "    times = []\n",
    "    for _ in range(n_runs):\n",
    "        start = time.perf_counter()\n",
    "        result = session.run(query, params or {})\n",
    "        _ = list(result)  # 결과 소비 (실제 실행 보장)\n",
    "        elapsed = (time.perf_counter() - start) * 1000  # ms\n",
    "        times.append(elapsed)\n",
    "    return times\n",
    "\n",
    "# 벤치마크 쿼리들\n",
    "benchmark_queries = [\n",
    "    {\n",
    "        \"name\": \"단일 노드 조회 (이름)\",\n",
    "        \"query\": \"MATCH (c:Company {name: $name}) RETURN c\",\n",
    "        \"params\": {\"name\": \"삼성전자\"}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"1-hop 이웃 탐색\",\n",
    "        \"query\": \"MATCH (c:Company {name: $name})-[r]-(n) RETURN c, type(r), n\",\n",
    "        \"params\": {\"name\": \"삼성전자\"}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"2-hop 경로 탐색\",\n",
    "        \"query\": \"MATCH path = (c:Company {name: $name})-[*1..2]-(n) RETURN path LIMIT 20\",\n",
    "        \"params\": {\"name\": \"삼성전자\"}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"전체 노드 카운트\",\n",
    "        \"query\": \"MATCH (n) RETURN count(n) AS cnt\",\n",
    "        \"params\": {}\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"=== 쿼리 성능 벤치마크 (10회 반복) ===\")\n",
    "bench_results = []\n",
    "\n",
    "with driver.session() as session:\n",
    "    for bq in benchmark_queries:\n",
    "        try:\n",
    "            times = benchmark_query(session, bq[\"query\"], bq[\"params\"])\n",
    "            avg_ms = sum(times) / len(times)\n",
    "            min_ms = min(times)\n",
    "            max_ms = max(times)\n",
    "            p50 = sorted(times)[len(times)//2]\n",
    "            \n",
    "            bench_results.append({\n",
    "                \"쿼리\": bq[\"name\"],\n",
    "                \"평균(ms)\": round(avg_ms, 2),\n",
    "                \"최소(ms)\": round(min_ms, 2),\n",
    "                \"최대(ms)\": round(max_ms, 2),\n",
    "                \"P50(ms)\": round(p50, 2)\n",
    "            })\n",
    "            print(f\"  {bq['name']:25s}: 평균 {avg_ms:.2f}ms (min={min_ms:.2f}, max={max_ms:.2f})\")\n",
    "        except Exception as e:\n",
    "            print(f\"  {bq['name']:25s}: 실행 실패 - {e}\")\n",
    "\n",
    "df_bench = pd.DataFrame(bench_results)\n",
    "print(\"\\n\")\n",
    "print(df_bench.to_string(index=False))"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec5-benchmark"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 5-3. APOC 프로시저 활용: 배치 처리\n",
    "# ============================================================\n",
    "print(\"=== APOC 배치 처리 예시 ===\")\n",
    "print(\"\"\"  \n",
    "# 대량 데이터 배치 업데이트 (1000건씩)\n",
    "# 프로덕션에서 수만 건 이상 처리 시 필수\n",
    "\n",
    "CALL apoc.periodic.iterate(\n",
    "  \"MATCH (c:Company) RETURN c\",\n",
    "  \"SET c.updated_at = datetime()\",\n",
    "  {batchSize: 1000, parallel: true}\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# APOC 사용 가능 여부 확인\n",
    "with driver.session() as session:\n",
    "    try:\n",
    "        result = session.run(\"RETURN apoc.version() AS version\")\n",
    "        version = result.single()[\"version\"]\n",
    "        print(f\"APOC 버전: {version}\")\n",
    "        \n",
    "        # 배치 처리 데모 (읽기 전용 — 안전)\n",
    "        result = session.run(\"\"\"\n",
    "            CALL apoc.periodic.iterate(\n",
    "                \"MATCH (n) RETURN n LIMIT 100\",\n",
    "                \"RETURN count(n)\",\n",
    "                {batchSize: 10, parallel: false}\n",
    "            )\n",
    "            YIELD batches, total, timeTaken\n",
    "            RETURN batches, total, timeTaken\n",
    "        \"\"\")\n",
    "        for record in result:\n",
    "            print(f\"  배치 수: {record['batches']}, 총 처리: {record['total']}, 소요: {record['timeTaken']}s\")\n",
    "    except Exception as e:\n",
    "        print(f\"APOC 미설치 또는 비활성: {e}\")\n",
    "        print(\"  -> docker-compose.yml에서 NEO4J_PLUGINS: '[\\\"apoc\\\"]' 확인\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec5-apoc"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 5-4. EXPLAIN/PROFILE로 쿼리 실행 계획 분석\n",
    "# ============================================================\n",
    "print(\"=== 쿼리 실행 계획 분석 ===\")\n",
    "\n",
    "with driver.session() as session:\n",
    "    # PROFILE: 실제 실행하면서 각 단계 통계 수집\n",
    "    profile_query = \"\"\"\n",
    "    PROFILE\n",
    "    MATCH (c:Company {name: \"삼성전자\"})-[r]-(neighbor)\n",
    "    RETURN c.name, type(r) AS rel_type, labels(neighbor) AS neighbor_labels,\n",
    "           neighbor.name AS neighbor_name\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        result = session.run(profile_query)\n",
    "        records = list(result)\n",
    "        \n",
    "        # 실행 결과\n",
    "        print(f\"\\n결과 행 수: {len(records)}\")\n",
    "        for rec in records[:5]:\n",
    "            print(f\"  {rec['c.name']} -[{rec['rel_type']}]-> \"\n",
    "                  f\"{rec['neighbor_labels']}: {rec['neighbor_name']}\")\n",
    "        \n",
    "        # 프로파일 정보\n",
    "        summary = result.consume()\n",
    "        if hasattr(summary, 'profile') and summary.profile:\n",
    "            profile = summary.profile\n",
    "            print(f\"\\n실행 계획:\")\n",
    "            print(f\"  DB Hits: {profile.get('dbHits', 'N/A')}\")\n",
    "            print(f\"  Rows: {profile.get('rows', 'N/A')}\")\n",
    "            print(f\"  Plan: {profile.get('operatorType', 'N/A')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"PROFILE 실행 실패: {e}\")\n",
    "        print(\"  -> 일반 MATCH 쿼리로 대체\")\n",
    "\n",
    "# 실행 계획 해석 가이드\n",
    "print(\"\\n=== 실행 계획 해석 가이드 ===\")\n",
    "print(\"\"\"\n",
    "| 연산자           | 의미                        | 최적화 포인트       |\n",
    "|------------------|----------------------------|--------------------|\n",
    "| NodeByLabelScan  | 라벨 전체 스캔              | 인덱스 추가 필요    |\n",
    "| NodeIndexSeek    | 인덱스 활용 (좋음)          | 최적 상태           |\n",
    "| Filter           | 결과 필터링                 | WHERE 조건 최적화   |\n",
    "| Expand(All)      | 관계 탐색                   | depth 제한 확인     |\n",
    "| CartesianProduct | 교차곱 (위험!)              | MATCH 패턴 재설계   |\n",
    "\n",
    "핵심: NodeByLabelScan → NodeIndexSeek으로 바꾸면 성능 10배 이상 향상\n",
    "\"\"\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec5-profile"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 5-5. 메모리 설정 권장값\n",
    "# ============================================================\n",
    "print(\"=== Neo4j 메모리 설정 권장값 ===\")\n",
    "print(\"\"\"\n",
    "# neo4j.conf 또는 docker-compose.yml 환경변수\n",
    "\n",
    "# ---- 개발 환경 (노드 ~10K) ----\n",
    "NEO4J_server_memory_heap_initial__size=512m\n",
    "NEO4J_server_memory_heap_max__size=1g\n",
    "NEO4J_server_memory_pagecache_size=512m\n",
    "\n",
    "# ---- 프로덕션 환경 (노드 ~1M) ----\n",
    "NEO4J_server_memory_heap_initial__size=4g\n",
    "NEO4J_server_memory_heap_max__size=4g\n",
    "NEO4J_server_memory_pagecache_size=8g\n",
    "\n",
    "# ---- 대규모 환경 (노드 ~10M+) ----\n",
    "NEO4J_server_memory_heap_initial__size=8g\n",
    "NEO4J_server_memory_heap_max__size=8g\n",
    "NEO4J_server_memory_pagecache_size=16g\n",
    "\n",
    "# 권장 공식:\n",
    "#   Page Cache = 데이터 크기 * 1.2\n",
    "#   Heap = min(31g, 서버 메모리 * 0.25)\n",
    "#   나머지 = OS + 파일 시스템 캐시\n",
    "\"\"\")\n",
    "\n",
    "# 현재 Neo4j 상태 확인\n",
    "with driver.session() as session:\n",
    "    try:\n",
    "        result = session.run(\"\"\"\n",
    "            CALL dbms.components() YIELD name, versions, edition\n",
    "            RETURN name, versions, edition\n",
    "        \"\"\")\n",
    "        for record in result:\n",
    "            print(f\"현재 Neo4j: {record['name']} {record['versions']} ({record['edition']})\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # 그래프 크기 확인\n",
    "    try:\n",
    "        result = session.run(\"\"\"\n",
    "            MATCH (n) WITH count(n) AS nodes\n",
    "            MATCH ()-[r]->() WITH nodes, count(r) AS rels\n",
    "            RETURN nodes, rels\n",
    "        \"\"\")\n",
    "        record = result.single()\n",
    "        if record:\n",
    "            print(f\"현재 그래프 크기: 노드 {record['nodes']}개, 관계 {record['rels']}개\")\n",
    "    except Exception as e:\n",
    "        print(f\"그래프 크기 확인 실패: {e}\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec5-memory"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. 프로덕션 체크리스트\n",
    "\n",
    "GraphRAG를 프로덕션에 배포하기 위한 **4가지 핵심 영역**을 점검합니다.\n",
    "\n",
    "### 6-1. 데이터 파이프라인\n",
    "\n",
    "```\n",
    "소스 데이터 → [추출] → [정제] → [적재] → [인덱싱] → Neo4j\n",
    "    |            |         |         |          |\n",
    "    PDF/HTML     LLM       ER        Cypher     인덱스\n",
    "    DB/API       VLM       검증      배치처리   풀텍스트\n",
    "```\n",
    "\n",
    "| 단계 | 도구 | 주의점 |\n",
    "|------|------|--------|\n",
    "| 추출 | GPT-4o, Claude | 프롬프트 버전 관리, 비용 모니터링 |\n",
    "| 정제 | Entity Resolution (Part 4) | 중복 임계값 튜닝 (0.85 권장) |\n",
    "| 적재 | neo4j Python driver | 배치 UNWIND, 트랜잭션 관리 |\n",
    "| 인덱싱 | CREATE INDEX | 라벨별 프로퍼티 인덱스 필수 |\n",
    "\n",
    "### 6-2. 모니터링\n",
    "\n",
    "| 모니터링 대상 | 도구 | 임계값 |\n",
    "|---------------|------|--------|\n",
    "| 쿼리 성능 | Neo4j Browser / LangSmith | P95 < 500ms |\n",
    "| 그래프 크기 | `MATCH (n) RETURN count(n)` | 주간 추적 |\n",
    "| LLM API 비용 | OpenAI Usage Dashboard | 일일 예산 설정 |\n",
    "| RAGAS 점수 | 주기적 평가 (주 1회) | 평균 > 0.7 |\n",
    "| 에러율 | 애플리케이션 로그 | < 1% |\n",
    "\n",
    "### 6-3. CI/CD\n",
    "\n",
    "```yaml\n",
    "# .github/workflows/graphrag-ci.yml\n",
    "name: GraphRAG CI\n",
    "on: [push, pull_request]\n",
    "jobs:\n",
    "  test:\n",
    "    runs-on: ubuntu-latest\n",
    "    services:\n",
    "      neo4j:\n",
    "        image: neo4j:5-community\n",
    "        env:\n",
    "          NEO4J_AUTH: neo4j/testpassword\n",
    "          NEO4J_PLUGINS: '[\"apoc\"]'\n",
    "        ports: [\"7687:7687\"]\n",
    "    steps:\n",
    "      - uses: actions/checkout@v4\n",
    "      - run: pip install -r requirements.txt\n",
    "      - run: python -m pytest tests/ -v\n",
    "      - run: python eval/run_ragas.py --threshold 0.7\n",
    "```\n",
    "\n",
    "**스키마 변경 관리:**\n",
    "- 스키마 변경은 마이그레이션 스크립트로 관리\n",
    "- `schema/v1.cypher`, `schema/v2.cypher` 형태로 버전 관리\n",
    "- 테스트 환경에서 먼저 적용 후 프로덕션 배포\n",
    "\n",
    "### 6-4. 보안\n",
    "\n",
    "| 항목 | 설정 | 이유 |\n",
    "|------|------|------|\n",
    "| 읽기 전용 사용자 | `GRANT READ ON DATABASE * TO reader` | API 서버에서 사용 |\n",
    "| 쿼리 검증 | Cypher injection 방지 (파라미터화) | Text2Cypher 출력 검증 |\n",
    "| API 키 관리 | 환경변수 / Secret Manager | `.env` 절대 커밋 금지 |\n",
    "| 네트워크 | VPC 내부에서만 Neo4j 접근 | 7687 포트 외부 차단 |"
   ],
   "id": "sec6-checklist"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 6-5. 프로덕션 체크리스트 자가진단 스크립트\n",
    "# ============================================================\n",
    "def production_checklist():\n",
    "    \"\"\"프로덕션 배포 전 자동 체크리스트를 실행합니다.\"\"\"\n",
    "    checks = []\n",
    "    \n",
    "    # 1. Neo4j 연결 확인\n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            session.run(\"RETURN 1\")\n",
    "        checks.append((\"Neo4j 연결\", \"PASS\", \"정상 연결\"))\n",
    "    except Exception as e:\n",
    "        checks.append((\"Neo4j 연결\", \"FAIL\", str(e)))\n",
    "    \n",
    "    # 2. 인덱스 존재 확인\n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            result = session.run(\"SHOW INDEXES YIELD name RETURN count(*) AS cnt\")\n",
    "            cnt = result.single()[\"cnt\"]\n",
    "            status = \"PASS\" if cnt >= 3 else \"WARN\"\n",
    "            checks.append((\"인덱스\", status, f\"{cnt}개 인덱스\"))\n",
    "    except Exception:\n",
    "        checks.append((\"인덱스\", \"FAIL\", \"확인 불가\"))\n",
    "    \n",
    "    # 3. 그래프 데이터 존재 확인\n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            result = session.run(\"MATCH (n) RETURN count(n) AS cnt\")\n",
    "            cnt = result.single()[\"cnt\"]\n",
    "            status = \"PASS\" if cnt > 0 else \"FAIL\"\n",
    "            checks.append((\"그래프 데이터\", status, f\"노드 {cnt}개\"))\n",
    "    except Exception:\n",
    "        checks.append((\"그래프 데이터\", \"FAIL\", \"확인 불가\"))\n",
    "    \n",
    "    # 4. OpenAI API 키 확인\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "    if api_key and len(api_key) > 10:\n",
    "        checks.append((\"OpenAI API 키\", \"PASS\", f\"...{api_key[-4:]}\"))\n",
    "    else:\n",
    "        checks.append((\"OpenAI API 키\", \"FAIL\", \"미설정\"))\n",
    "    \n",
    "    # 5. APOC 플러그인\n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            result = session.run(\"RETURN apoc.version() AS v\")\n",
    "            v = result.single()[\"v\"]\n",
    "            checks.append((\"APOC 플러그인\", \"PASS\", f\"v{v}\"))\n",
    "    except Exception:\n",
    "        checks.append((\"APOC 플러그인\", \"WARN\", \"미설치 (선택사항)\"))\n",
    "    \n",
    "    # 6. 쿼리 성능\n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            start = time.perf_counter()\n",
    "            session.run(\"MATCH (n) RETURN n LIMIT 100\").consume()\n",
    "            elapsed_ms = (time.perf_counter() - start) * 1000\n",
    "            status = \"PASS\" if elapsed_ms < 100 else (\"WARN\" if elapsed_ms < 500 else \"FAIL\")\n",
    "            checks.append((\"쿼리 성능 (100노드)\", status, f\"{elapsed_ms:.1f}ms\"))\n",
    "    except Exception:\n",
    "        checks.append((\"쿼리 성능\", \"FAIL\", \"측정 불가\"))\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(\"=\" * 60)\n",
    "    print(\"  프로덕션 배포 체크리스트\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    pass_count = 0\n",
    "    for name, status, detail in checks:\n",
    "        icon = {\"PASS\": \"[OK]\", \"WARN\": \"[!!]\", \"FAIL\": \"[XX]\"}[status]\n",
    "        print(f\"  {icon} {name:25s} {detail}\")\n",
    "        if status == \"PASS\":\n",
    "            pass_count += 1\n",
    "    \n",
    "    print(f\"\\n  결과: {pass_count}/{len(checks)} 통과\")\n",
    "    if pass_count == len(checks):\n",
    "        print(\"  -> 프로덕션 배포 준비 완료!\")\n",
    "    else:\n",
    "        print(\"  -> 위 항목을 확인 후 배포하세요.\")\n",
    "\n",
    "production_checklist()"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec6-script"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. 최종 아키텍처 요약\n",
    "\n",
    "### Part 1~7 전체 파이프라인\n",
    "\n",
    "```\n",
    " [Part 1] 동기 부여                    [Part 7] 프로덕션\n",
    "    |                                      ^\n",
    "    v                                      |\n",
    " [Part 2] 수작업 KG    ──────────>    RAGAS 평가\n",
    "    |                                 Neo4j 최적화\n",
    "    v                                 CI/CD + 모니터링\n",
    " [Part 3] LLM 자동 추출                    ^\n",
    "    |                                      |\n",
    "    v                                      |\n",
    " [Part 4] Entity Resolution ────>   정제된 KG\n",
    "    |                                      |\n",
    "    v                                      |\n",
    " [Part 5] 멀티모달 VLM ─────────>   통합 KG (텍스트+표+이미지)\n",
    "    |                                      |\n",
    "    v                                      v\n",
    " [Part 6] 검색 파이프라인 ──────>   GraphRAG 시스템 완성\n",
    "           Text2Cypher Agent\n",
    "           하이브리드 검색\n",
    "           답변 생성\n",
    "```\n",
    "\n",
    "### 각 Part 핵심 기술 정리\n",
    "\n",
    "| Part | 핵심 | 기술 스택 | Milestone |\n",
    "|------|------|-----------|------------|\n",
    "| **1** | 왜 GraphRAG인가 | Neo4j, Cypher 기초 | 첫 그래프 생성 (7노드) |\n",
    "| **2** | 수작업 KG 구축 | 온톨로지, Meta-Dictionary | 수작업 KG (15노드, 20관계) |\n",
    "| **3** | LLM 자동 추출 | GPT-4o, Structured Output | 자동 KG 생성 |\n",
    "| **4** | Entity Resolution | RapidFuzz, 임베딩 유사도 | 중복 제거 완료 |\n",
    "| **5** | 멀티모달 VLM | GPT-4o Vision, 표 파싱 | 텍스트+표 통합 KG |\n",
    "| **6** | 검색 파이프라인 | Text2Cypher, 하이브리드 | GraphRAG 시스템 완성 |\n",
    "| **7** | 평가 + 프로덕션 | RAGAS, 인덱스, CI/CD | 프로덕션 배포 준비 |\n",
    "\n",
    "### 다음 단계 추천\n",
    "\n",
    "이 커리큘럼을 마친 후 도전할 수 있는 고급 주제:\n",
    "\n",
    "1. **고급 그래프 알고리즘** — PageRank, Betweenness Centrality로 핵심 노드 발견\n",
    "2. **커뮤니티 탐지** — Louvain, Label Propagation으로 클러스터링\n",
    "3. **GNN (Graph Neural Network)** — PyG, DGL로 그래프 기반 딥러닝\n",
    "4. **Microsoft GraphRAG** — 글로벌 검색 + 커뮤니티 요약\n",
    "5. **멀티 도메인 통합** — 여러 도메인 그래프를 통합하는 전사 KG"
   ],
   "id": "sec7-architecture"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 7-1. 전체 커리큘럼 완료 요약 출력\n",
    "# ============================================================\n",
    "summary = \"\"\"\n",
    "============================================================\n",
    "   GraphRAG 실습 커리큘럼 — 전체 완료 요약\n",
    "============================================================\n",
    "\n",
    "Part 1: 왜 GraphRAG인가?\n",
    "  -> Neo4j에 첫 그래프 생성 완료 (노드 7개 + 관계 5개)\n",
    "\n",
    "Part 2: 수작업 KG 구축\n",
    "  -> 온톨로지 설계 + Meta-Dictionary 작성 완료\n",
    "\n",
    "Part 3: LLM 자동 추출\n",
    "  -> GPT-4o로 뉴스 10건에서 자동 KG 생성 완료\n",
    "\n",
    "Part 4: Entity Resolution\n",
    "  -> RapidFuzz + 임베딩으로 중복 엔티티 해소 완료\n",
    "\n",
    "Part 5: 멀티모달 VLM\n",
    "  -> 표/이미지 문서를 그래프로 변환 완료\n",
    "\n",
    "Part 6: 통합 + 검색\n",
    "  -> Text2Cypher Agent + 하이브리드 검색 시스템 완성\n",
    "\n",
    "Part 7: 평가 + 프로덕션 (현재)\n",
    "  -> RAGAS 평가 + Neo4j 최적화 + 프로덕션 체크리스트 완료\n",
    "\n",
    "============================================================\n",
    "  핵심 메시지 7줄\n",
    "============================================================\n",
    "\n",
    "  1. 문제 정의가 먼저 — GraphRAG부터 시작하지 마라\n",
    "  2. 암묵지를 Meta-Dictionary로 체계화\n",
    "  3. 표는 SQL, 문서는 계층 — 각각 다르게 접근\n",
    "  4. 가중치 싸움이 디자인을 결정\n",
    "  5. Text2Cypher = 삽질의 연속 -> Agent로 해결\n",
    "  6. 1-hop이면 벡터로 충분 — Multi-hop이 존재 이유\n",
    "  7. 정답은 없다 — PoC, 상황별 선택, 교차 평가\n",
    "\n",
    "============================================================\n",
    "  수고하셨습니다! 이제 여러분의 프로젝트에 적용해보세요.\n",
    "============================================================\n",
    "\"\"\"\n",
    "print(summary)"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec7-summary"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. 연습 문제\n",
    "\n",
    "### 연습 8-1: 자신만의 평가 질문 5개 추가\n",
    "\n",
    "아래 템플릿을 사용하여 **본인 도메인에 맞는 평가 질문 5개**를 작성하세요.  \n",
    "난이도를 골고루 포함하는 것이 좋습니다 (Easy 1, Medium 2, Hard 2)."
   ],
   "id": "sec8-title"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 연습 8-1: 자신만의 평가 질문 작성\n",
    "# ============================================================\n",
    "\n",
    "# TODO: 아래 질문을 본인 도메인에 맞게 수정하세요\n",
    "my_questions = [\n",
    "    {\n",
    "        \"question\": \"여기에 Easy 질문을 작성하세요\",\n",
    "        \"ground_truth\": \"정답\",\n",
    "        \"difficulty\": \"easy\",\n",
    "        \"hops\": 1\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"여기에 Medium 질문을 작성하세요 (1)\",\n",
    "        \"ground_truth\": \"정답\",\n",
    "        \"difficulty\": \"medium\",\n",
    "        \"hops\": 2\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"여기에 Medium 질문을 작성하세요 (2)\",\n",
    "        \"ground_truth\": \"정답\",\n",
    "        \"difficulty\": \"medium\",\n",
    "        \"hops\": 2\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"여기에 Hard 질문을 작성하세요 (1)\",\n",
    "        \"ground_truth\": \"정답\",\n",
    "        \"difficulty\": \"hard\",\n",
    "        \"hops\": 3\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"여기에 Hard 질문을 작성하세요 (2)\",\n",
    "        \"ground_truth\": \"정답\",\n",
    "        \"difficulty\": \"hard\",\n",
    "        \"hops\": 3\n",
    "    }\n",
    "]\n",
    "\n",
    "# 작성 후 아래 코드로 검증\n",
    "for i, q in enumerate(my_questions):\n",
    "    print(f\"{i+1}. [{q['difficulty']:6s}] {q['question']}\")\n",
    "    print(f\"   정답: {q['ground_truth']}\")\n",
    "\n",
    "# 선택: RAGAS 평가 실행\n",
    "# my_results = run_rag_pipeline(my_questions, graph_search, \"Custom\")\n",
    "# my_scores = evaluate(my_results[\"dataset\"], metrics=[faithfulness, answer_relevancy])\n",
    "# print(my_scores)"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec8-custom-questions"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습 8-2: 인덱스 전략 실험\n",
    "\n",
    "다양한 인덱스 전략을 실험하고, 쿼리 성능 변화를 측정하세요."
   ],
   "id": "sec8-2-title"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 연습 8-2: 인덱스 전략 실험\n",
    "# ============================================================\n",
    "\n",
    "# TODO: 다양한 인덱스를 만들고 벤치마크를 비교하세요\n",
    "\n",
    "# 실험 1: 복합 인덱스 (여러 프로퍼티)\n",
    "# with driver.session() as session:\n",
    "#     session.run(\"\"\"\n",
    "#         CREATE INDEX company_name_sector IF NOT EXISTS\n",
    "#         FOR (c:Company) ON (c.name, c.sector)\n",
    "#     \"\"\")\n",
    "\n",
    "# 실험 2: 관계 인덱스 (Neo4j 5.7+)\n",
    "# with driver.session() as session:\n",
    "#     session.run(\"\"\"\n",
    "#         CREATE INDEX rel_invested IF NOT EXISTS\n",
    "#         FOR ()-[r:INVESTED_IN]-() ON (r.amount)\n",
    "#     \"\"\")\n",
    "\n",
    "# 실험 3: 인덱스 유무에 따른 벤치마크 비교\n",
    "# 힌트: benchmark_query() 함수를 활용하세요\n",
    "\n",
    "print(\"인덱스 전략 실험 셀입니다.\")\n",
    "print(\"위의 주석을 해제하고 실행하여 실험해보세요.\")\n",
    "print(\"\")\n",
    "print(\"실험 포인트:\")\n",
    "print(\"  1. 단일 프로퍼티 인덱스 vs 복합 인덱스\")\n",
    "print(\"  2. 풀텍스트 인덱스의 한국어 지원 확인\")\n",
    "print(\"  3. PROFILE로 인덱스 사용 여부 확인\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec8-index-experiment"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습 8-3: End-to-End 파이프라인 테스트\n",
    "\n",
    "Part 1~7 전체 파이프라인을 하나의 함수로 통합하고 테스트하세요."
   ],
   "id": "sec8-3-title"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 연습 8-3: End-to-End 파이프라인 테스트\n",
    "# ============================================================\n",
    "\n",
    "def end_to_end_graphrag(question: str, verbose: bool = True) -> dict:\n",
    "    \"\"\"GraphRAG 전체 파이프라인을 실행합니다.\n",
    "    \n",
    "    1. 질문 분석 (난이도 추정)\n",
    "    2. 검색 (그래프 탐색)\n",
    "    3. 답변 생성\n",
    "    4. 자체 품질 점검\n",
    "    \n",
    "    Returns:\n",
    "        dict: question, answer, contexts, metadata\n",
    "    \"\"\"\n",
    "    start_total = time.time()\n",
    "    \n",
    "    # 1단계: 질문 분석\n",
    "    if verbose:\n",
    "        print(f\"질문: {question}\")\n",
    "        print(\"---\")\n",
    "    \n",
    "    # 2단계: 그래프 검색\n",
    "    t0 = time.time()\n",
    "    contexts = graph_search(question, depth=2)\n",
    "    search_time = time.time() - t0\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"[검색] {len(contexts)}개 문맥 ({search_time:.2f}s)\")\n",
    "    \n",
    "    # 3단계: 답변 생성\n",
    "    t0 = time.time()\n",
    "    answer = generate_answer(question, contexts)\n",
    "    gen_time = time.time() - t0\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"[생성] {gen_time:.2f}s\")\n",
    "        print(f\"답변: {answer}\")\n",
    "    \n",
    "    # 4단계: 자체 품질 점검\n",
    "    total_time = time.time() - start_total\n",
    "    \n",
    "    result = {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "        \"contexts\": contexts,\n",
    "        \"metadata\": {\n",
    "            \"context_count\": len(contexts),\n",
    "            \"search_time_s\": round(search_time, 3),\n",
    "            \"gen_time_s\": round(gen_time, 3),\n",
    "            \"total_time_s\": round(total_time, 3)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n총 소요시간: {total_time:.2f}s\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# 테스트 실행\n",
    "print(\"=== End-to-End 테스트 ===\")\n",
    "print()\n",
    "\n",
    "test_questions = [\n",
    "    \"삼성전자가 양산을 시작한 차세대 메모리는?\",\n",
    "    \"네이버와 삼성전자가 공동 개발한 기술이 적용될 기기는?\",\n",
    "    \"반도체 기업 두 곳의 경쟁 관계를 설명하면?\"\n",
    "]\n",
    "\n",
    "for q in test_questions:\n",
    "    print(\"=\" * 50)\n",
    "    result = end_to_end_graphrag(q)\n",
    "    print()"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "sec8-e2e"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 정리: Neo4j 연결 종료\n",
    "# ============================================================\n",
    "driver.close()\n",
    "print(\"Neo4j 연결 종료\")\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"  Part 7 완료 — GraphRAG 실습 커리큘럼을 마칩니다.\")\n",
    "print(\"  수고하셨습니다!\")\n",
    "print(\"=\" * 60)"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "cleanup"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}